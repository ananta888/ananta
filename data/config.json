{
  "agents": {
    "default": {
      "model": "llama3",
      "template": "default",
      "max_summary_length": 300,
      "step_delay": 10,
      "auto_restart": false,
      "allow_commands": true,
      "controller_active": true,
      "prompt": "",
      "tasks": []
    }
  },
  "active_agent": "default",
  "prompt_templates": {
    "default": "{task}"
  },
  "api_endpoints": [
    {
      "type": "lmstudio",
      "url": "http://host.docker.internal:1234/v1/chat/completions"
    }
  ],
  "tasks": [],
  "pipeline_order": [
    "default"
  ]
}