{
  "backend-2026-02-17-benchmark-sample-retention-and-pruning-controls": {
    "id": "backend-2026-02-17-benchmark-sample-retention-and-pruning-controls",
    "title": "Benchmark-Samples: Retention/Pruning konfigurierbar machen",
    "status": "todo",
    "priority": "medium",
    "rank": 1,
    "type": "backend",
    "details": "Timeseries-Samples werden aktuell mit fixem Limit gehalten. Konfigurierbare Retention (z.B. max_samples/max_days) und optionales Pruning beim Lesen/Schreiben ergaenzen, um Datenwachstum langfristig kontrolliert zu halten.",
    "observed_at": "2026-02-17"
  },
  "backend-2026-02-17-benchmark-fallback-precedence-config-and-doc": {
    "id": "backend-2026-02-17-benchmark-fallback-precedence-config-and-doc",
    "title": "Benchmark-Fallback-Prioritaet explizit konfigurierbar und dokumentieren",
    "status": "todo",
    "priority": "medium",
    "rank": 2,
    "type": "backend",
    "details": "Aktuell greift bei fehlender Proposal-Meta zuerst llm_config vor default_provider/default_model. Reihenfolge explizit konfigurierbar machen und dokumentieren, um unerwartete Zuordnungseffekte zu vermeiden.",
    "observed_at": "2026-02-17"
  },
  "backend-2026-02-17-llm-generate-routing-metadata-in-error-responses": {
    "id": "backend-2026-02-17-llm-generate-routing-metadata-in-error-responses",
    "title": "LLM-Generate: Routing-Metadaten auch in Error-Responses mitgeben",
    "status": "todo",
    "priority": "medium",
    "rank": 3,
    "type": "backend",
    "details": "Routing-Metadaten werden aktuell fuer erfolgreiche /llm/generate-Pfade geliefert, bei fruehen Fehlern (z.B. provider/base_url/api_key) jedoch nicht konsistent. Fehlerantworten um dieselben Meta-Felder erweitern.",
    "observed_at": "2026-02-17"
  },
  "qa-2026-02-17-e2e-coverage-for-cli-backends-model-catalog-and-benchmarks": {
    "id": "qa-2026-02-17-e2e-coverage-for-cli-backends-model-catalog-and-benchmarks",
    "title": "Automatisierte Tests fuer CLI-Backends, Modellkatalog und Benchmark-Flow ergaenzen",
    "status": "todo",
    "priority": "medium",
    "rank": 4,
    "type": "qa",
    "details": "Regression- und E2E-Tests erweitern: opencode/aider in Propose/Autopilot, dynamischer Modellkatalog (LM Studio online/offline), sowie Benchmark-Auswertung und Empfehlungspfade im Frontend.",
    "observed_at": "2026-02-17"
  },
  "backend-2026-02-17-multi-provider-compare-still-bypasses-cli-routing": {
    "id": "backend-2026-02-17-multi-provider-compare-still-bypasses-cli-routing",
    "title": "Multi-Provider-Vergleich in task_propose auf CLI-Routing umstellen",
    "status": "todo",
    "priority": "medium",
    "rank": 5,
    "type": "backend",
    "details": "Der branch mit data.providers in /tasks/<tid>/step/propose verwendet weiterhin _call_llm pro Provider-ID und damit keinen CLI-Backend-Pfad. Vergleichsmodus fuer opencode/aider/mistral_code umziehen oder separat als Provider-only-Modus klar kennzeichnen.",
    "observed_at": "2026-02-17"
  },
  "backend-2026-02-17-provider-catalog-caching-and-timeout-controls": {
    "id": "backend-2026-02-17-provider-catalog-caching-and-timeout-controls",
    "title": "Provider-Katalog: Caching/Timeout-Steuerung fuer LM-Studio-Abfragen ergaenzen",
    "status": "todo",
    "priority": "medium",
    "rank": 6,
    "type": "backend",
    "details": "Dynamische Katalogabfragen nutzen aktuell feste Timeout-Werte und keinen expliziten Cache. Endpoint-Optionen fuer Cache-TTL/force-refresh plus konfigurierbare Timeouts ergaenzen, um UI-Latenz bei instabilen lokalen LLM-Endpoints zu reduzieren.",
    "observed_at": "2026-02-17"
  },
  "fe-2026-02-17-xterm-commonjs-optimization-bailout": {
    "id": "fe-2026-02-17-xterm-commonjs-optimization-bailout",
    "title": "Angular Build: CommonJS-Warnungen fuer xterm/addon-fit reduzieren",
    "status": "todo",
    "priority": "low",
    "rank": 7,
    "type": "frontend",
    "details": "Beim Build treten Optimierungswarnungen fuer @xterm/xterm und @xterm/addon-fit (nicht ESM) auf. Build-Konfiguration/Imports so anpassen, dass Bundle-Optimierung verbessert oder Warnungen bewusst konfiguriert behandelt werden.",
    "observed_at": "2026-02-17"
  }
}