[
  {
    "id": "AGENT-1",
    "title": "Verbesserung des LLM-Response Parsings",
    "type": "improvement",
    "priority": "medium",
    "files": ["agent/utils.py"],
    "details": "Die Extraktion von Befehlen und Begründungen aus LLM-Antworten in `_extract_command` und `_extract_reason` sollte robuster gegenüber beschädigtem JSON oder unvollständigen Markdown-Blöcken gemacht werden. Eventuell 'dirty-json' Ansätze oder verbesserte Regex nutzen."
  },
  {
    "id": "AGENT-2",
    "title": "Erweiterung der LLM-Healthchecks",
    "type": "improvement",
    "priority": "low",
    "files": ["agent/ai_agent.py", "agent/llm_integration.py"],
    "details": "Der aktuelle `_start_llm_check_thread` prüft die generelle Erreichbarkeit. Es wäre sinnvoll, auch die Latenz zu messen und bei Überschreitung eines Schwellenwerts den Provider temporär abzuwerten oder den Circuit Breaker früher auszulösen."
  },
  {
    "id": "DOCKER-3",
    "title": "Ressourcen-Limits für Container definieren",
    "type": "improvement",
    "priority": "low",
    "files": ["docker-compose.yml"],
    "details": "Für den stabilen Betrieb in Produktionsumgebungen sollten CPU- und Memory-Limits für die einzelnen Services (besonders AI-Agent und Redis) in der docker-compose.yml definiert werden."
  }
]
